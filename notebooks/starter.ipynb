{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aece24bd",
   "metadata": {},
   "source": [
    "# Starter Notebook — Flood Risk Prediction\n",
    "\n",
    "This notebook contains runnable, well-commented examples for: downloading Sentinel samples (instructions), reading GeoTIFFs with `rasterio`, basic preprocessing (NDVI, normalization), extracting tiles, a tiny Keras training example (placeholder), and visualization (heatmap & Folium overlay). Replace placeholders with your real data paths and credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96522e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and environment checks\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "print('Python executable:', os.sys.executable)\n",
    "print('Working directory:', Path.cwd())\n",
    "\n",
    "# Helper to check optional libraries without failing the notebook\n",
    "def check_libs():\n",
    "    libs = ['rasterio','rioxarray','sentinelsat','tensorflow','folium']\n",
    "    status = {}\n",
    "    for lib in libs:\n",
    "        try:\n",
    "            __import__(lib)\n",
    "            status[lib] = True\n",
    "        except Exception as e:\n",
    "            status[lib] = False\n",
    "    return status\n",
    "\n",
    "pprint(check_libs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9511301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory setup — update this to your local data folder\n",
    "DATA_DIR = Path('..') / 'data'\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Data dir:', DATA_DIR.resolve())\n",
    "\n",
    "# Show a few files if present\n",
    "files = list(DATA_DIR.rglob('*.*'))[:20]\n",
    "print('Found files:', len(files))\n",
    "for f in files[:10]:\n",
    "    print('-', f.name)\n",
    "\n",
    "if len(files)==0:\n",
    "    print('No sample files found. See the Sentinel-2 example cell below to download samples or place GeoTIFFs into the data/ folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7147026",
   "metadata": {},
   "source": [
    "## Sentinel-2 sample download (instructions)\n",
    "\n",
    "Automated download requires registering at Copernicus Open Access Hub and using `sentinelsat` or the AWS Public Datasets (if available for your region). The code below is a template — fill in your credentials and query parameters. If you prefer, manually download a small region's GeoTIFFs and place them in `data/`.\n",
    "\n",
    "Note: do NOT run the download cell unless you have sufficient disk and a registered account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbead35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentinelsat usage (template; commented out to avoid accidental runs)\n",
    "# from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "# user = 'your-username'\n",
    "# password = 'your-password'\n",
    "# api = SentinelAPI(user, password, 'https://scihub.copernicus.eu/dhus')\n",
    "# footprint = geojson_to_wkt(read_geojson('aoi.geojson'))\n",
    "# products = api.query(footprint, date=('20220101','20220115'), platformname='Sentinel-2', cloudcoverpercentage=(0,20))\n",
    "# print('Products found:', len(products))\n",
    "# api.download_all(products, directory_path=str(DATA_DIR))\n",
    "print('Template sentinelsat code shown (commented).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af96f7",
   "metadata": {},
   "source": [
    "## Read a single GeoTIFF with rasterio\n",
    "The cell below tries to open the first raster-like file in `data/` and displays basic band info. This uses `rasterio` if available and falls back to a placeholder image if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c16b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a GeoTIFF with rasterio (safe: wrapped in try/except)\n",
    "sample = None\n",
    "tif_files = [p for p in DATA_DIR.rglob('*.tif') if p.is_file()]\n",
    "if len(tif_files)>0:\n",
    "    fp = tif_files[0]\n",
    "    try:\n",
    "        import rasterio\n",
    "        with rasterio.open(fp) as src:\n",
    "            print('Raster CRS:', src.crs)\n",
    "            print('Raster size (w,h):', src.width, src.height)\n",
    "            bands = src.count\n",
    "            print('Band count:', bands)\n",
    "            arr = src.read([1,2,3])  # read first 3 bands (may be RGB or B,G,R depending on product)\n",
    "            # convert to HWC for display\n",
    "            img = np.moveaxis(arr, 0, -1)\n",
    "            sample = img\n",
    "    except Exception as e:\n",
    "        print('rasterio read failed:', e)\n",
    "        sample = None\n",
    "else:\n",
    "    print('No .tif files found in data/.')\n",
    "\n",
    "if sample is None:\n",
    "    # fallback placeholder\n",
    "    sample = np.clip(np.random.rand(256,256,3),0,1)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(sample[:,:, :3])\n",
    "plt.title('Sample (first 3 bands or placeholder)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06b5cc",
   "metadata": {},
   "source": [
    "## Compute NDVI (example)\n",
    "NDVI = (NIR - RED) / (NIR + RED). For Sentinel-2, band 8 is NIR (B08) and band 4 is Red (B04) — file formats vary. Adjust indexing based on your raster's band order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3667f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi(nir, red, eps=1e-6):\n",
    "    # nir, red: numpy arrays (H,W) or (H,W,1)\n",
    "    nir = nir.astype('float32')\n",
    "    red = red.astype('float32')\n",
    "    ndvi = (nir - red) / (nir + red + eps)\n",
    "    return ndvi\n",
    "\n",
    "# Demo: if `img` has NIR in channel 2 and RED in channel 0 (this is just illustrative)\n",
    "if sample is not None:\n",
    "    try:\n",
    "        # adapt the indices below to match your raster band order\n",
    "        red = sample[:,:,0]\n",
    "        nir = sample[:,:,2]\n",
    "        ndvi = compute_ndvi(nir, red)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.imshow(ndvi, cmap='RdYlGn')\n",
    "        plt.colorbar(label='NDVI')\n",
    "        plt.title('NDVI (demo)')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print('NDVI demo failed (band indices may be different):', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9df57",
   "metadata": {},
   "source": [
    "## Tile extraction / dataset creation (placeholder)\n",
    "Split large rasters into smaller tiles and save paired images + labels (if available). The code below is a template — adapt tile size, stride, and label logic to your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7247ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tiles(img, tile_size=256, stride=256):\n",
    "    h,w,_ = img.shape\n",
    "    tiles = []\n",
    "    for y in range(0, h-tile_size+1, stride):\n",
    "        for x in range(0, w-tile_size+1, stride):\n",
    "            tiles.append(img[y:y+tile_size, x:x+tile_size])\n",
    "    return tiles\n",
    "\n",
    "# Demo extract a few tiles from `sample`\n",
    "tiles = extract_tiles((sample*255).astype('uint8'), tile_size=128, stride=128)\n",
    "print('Extracted tiles:', len(tiles))\n",
    "plt.figure(figsize=(8,4))\n",
    "for i,t in enumerate(tiles[:6]):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(t[:,:, :3])\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Example tiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c31358",
   "metadata": {},
   "source": [
    "## Minimal Keras training example (placeholder)\n",
    "This example builds a tiny CNN and trains on random data to demonstrate the API; replace with your `tf.data` pipeline or ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models\n",
    "    tf_available = True\n",
    "except Exception as e:\n",
    "    print('TensorFlow not available:', e)\n",
    "    tf_available = False\n",
    "\n",
    "if tf_available:\n",
    "    # tiny model\n",
    "    model = models.Sequential([\n",
    "        layers.Input((128,128,3)),\n",
    "        layers.Conv2D(16,3,activation='relu'),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Conv2D(32,3,activation='relu'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # create tiny random dataset for demo\n",
    "    x = np.random.rand(8,128,128,3).astype('float32')\n",
    "    y = np.random.randint(0,3,size=(8,))\n",
    "    history = model.fit(x,y, epochs=1, batch_size=4)\n",
    "else:\n",
    "    print('Skipping model demo — install TensorFlow to run this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef677d9",
   "metadata": {},
   "source": [
    "## Visualization: heatmap & Folium (export)\n",
    "Create a heatmap from model predictions (per-tile) and either display with matplotlib or export geo-referenced tiles as GeoJSON/PNG for overlay in `folium` or QGIS. The cell below shows a simple matplotlib heatmap example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo heatmap from random 'risk' scores\n",
    "risk_map = np.random.rand(64,64)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(risk_map, cmap='hot')\n",
    "plt.colorbar(label='Flood risk (0-1)')\n",
    "plt.title('Demo flood risk heatmap')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# To overlay on folium: create an image overlay or tile layer from geo-referenced array (requires CRS and bounds). See README for folium link example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b6f2d",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "1. Replace placeholder tiles with real Sentinel-2/Sentinel-1 tiles (use `rasterio` or `xarray` to read and align bands).\n",
    "2. Implement label logic (e.g., pre/post flood masks or proxy labels from water segmentation).\n",
    "3. Build a `tf.data` pipeline that yields (image, label) pairs and use a transfer-learning backbone (ResNet50/EfficientNet).\n",
    "4. Export per-tile predictions to GeoTIFF/GeoJSON and visualize in `folium`/QGIS.\n",
    "\n",
    "If you'd like, I can now:\n",
    "- (A) Fill a notebook cell to automatically download a small Sentinel-2 sample (AWS or Copernicus template) and show the exact commands to run locally, OR\n",
    "- (B) Implement a full `src/data.py` + `src/model.py` + a runnable `train.py` that trains on a small bundled sample and includes unit tests.\n",
    "\n",
    "Reply with `download-sample` or `full-train` to pick the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c255f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Sentinel-2 sample download templates =====\n",
    "# 1) Using sentinelsat (Python) - fill credentials and footprint AOI\n",
    "# Uncomment and update before running:\n",
    "# from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "# user = 'your-username'\n",
    "# password = 'your-password'\n",
    "# api = SentinelAPI(user, password, 'https://scihub.copernicus.eu/dhus')\n",
    "# footprint = geojson_to_wkt(read_geojson('aoi.geojson'))\n",
    "# products = api.query(footprint, date=('20230101','20230115'), platformname='Sentinel-2', cloudcoverpercentage=(0,30))\n",
    "# print('Products found:', len(products))\n",
    "# api.download_all(products, directory_path=str(DATA_DIR))\n",
    "\n",
    "# 2) Using AWS CLI (recommended for public AWS-hosted tiles) - replace <S3_URI> with a real path\n",
    "# Example PowerShell command (run in your shell, not inside notebook):\n",
    "# aws s3 cp \"s3://<bucket>/<path-to-tile>.zip\" . --no-sign-request\n",
    "# unzip the archive and move the .SAFE or .tif files into the data/ folder\n",
    "\n",
    "# 3) Using boto3 (Python) to download an S3 object (works for public buckets with no auth)\n",
    "from pathlib import Path\n",
    "\n",
    "def download_s3_object(s3_uri, out_dir='.'):\n",
    "    \"\"\"Download an S3 object using boto3. s3_uri example: 's3://bucket/path/to/file.zip'\n",
    "    This function will only work if boto3 is installed and (for private buckets) AWS credentials are configured.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import boto3\n",
    "        from urllib.parse import urlparse\n",
    "    except Exception as e:\n",
    "        print('boto3 not available. Install boto3 to use this helper:', e)\n",
    "        return False\n",
    "    parsed = urlparse(s3_uri)\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path.lstrip('/')\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / Path(key).name\n",
    "    s3 = boto3.client('s3')\n",
    "    print(f'Downloading s3://{bucket}/{key} -> {out_path}')\n",
    "    try:\n",
    "        s3.download_file(bucket, key, str(out_path))\n",
    "        print('Download complete')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print('Download failed:', e)\n",
    "        return False\n",
    "\n",
    "# Usage examples (edit before running):\n",
    "# download_s3_object('s3://sentinel-sample-bucket/path/to/sample.zip', out_dir=str(DATA_DIR))\n",
    "# Or run the AWS CLI command from PowerShell (recommended for speed):\n",
    "# aws s3 cp \"s3://<bucket>/<tile>.zip\" . --no-sign-request\n",
    "\n",
    "print('Download templates available. Edit and run the appropriate command for your environment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Concrete public AWS example (discover and download a small Sentinel-2 file) =====\n",
    "# WARNING: inspect file size before downloading. Use the commands below to discover small sample files.\n",
    "# 1) List a few objects under the public Sentinel-2 L2A tiles bucket (no credentials needed):\n",
    "#    PowerShell example (run in your terminal, not in the notebook):\n",
    "#    aws s3 ls s3://sentinel-s2-l2a/tiles/ --no-sign-request | Select-Object -First 100\n",
    "#    The output shows prefixes (tile grid). Drill down to a year/date/prefix to find smaller files.\n",
    "#\n",
    "# 2) To list files in a specific tile prefix, e.g. tiles/10/UR/ABC (replace with prefix you found):\n",
    "#    aws s3 ls s3://sentinel-s2-l2a/tiles/10/UR/ABC/2020/10/10/0/ --no-sign-request\n",
    "#\n",
    "# 3) After you identify a small .jp2 or .zip file, download it with aws s3 cp (fast):\n",
    "#    aws s3 cp \"s3://sentinel-s2-l2a/tiles/10/UR/ABC/2020/10/10/0/B04.jp2\" . --no-sign-request\n",
    "#\n",
    "# 4) Or use the Python helper defined earlier (boto3) from the notebook (requires boto3):\n",
    "#    from src.download_sample import download_s3_object\n",
    "#    download_s3_object('s3://sentinel-s2-l2a/tiles/10/UR/ABC/2020/10/10/0/B04.jp2', out_dir=str(DATA_DIR))\n",
    "#\n",
    "# Notes:\n",
    "# - The bucket 'sentinel-s2-l2a' is a public AWS Open Data bucket (may be large). The example above uses the generic path structure for L2A tiles — replace the prefix with one you discover via `aws s3 ls`.\n",
    "# - If the file is large (>500MB), consider downloading only a single band (.jp2) or a small tile/preview instead of entire SAFE archives.\n",
    "# - The notebook will NOT download anything automatically; these are templates you should run in your PowerShell terminal after checking file sizes.\n",
    "\n",
    "print('Concrete AWS example cell added. Run the listed aws CLI commands in PowerShell to explore and download.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
